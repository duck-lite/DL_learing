{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5347c60f",
   "metadata": {},
   "source": [
    "# 1.数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c14967",
   "metadata": {},
   "source": [
    "## Step1.加载数据集（包含数据预处理） \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7233a73e",
   "metadata": {},
   "source": [
    "### 数据预处理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e546a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共找到 41 个 transforms 方法：\n",
      "AugMix\n",
      "AutoAugment\n",
      "AutoAugmentPolicy\n",
      "CenterCrop\n",
      "ColorJitter\n",
      "Compose\n",
      "ConvertImageDtype\n",
      "ElasticTransform\n",
      "FiveCrop\n",
      "GaussianBlur\n",
      "Grayscale\n",
      "InterpolationMode\n",
      "Lambda\n",
      "LinearTransformation\n",
      "Normalize\n",
      "PILToTensor\n",
      "Pad\n",
      "RandAugment\n",
      "RandomAdjustSharpness\n",
      "RandomAffine\n",
      "RandomApply\n",
      "RandomAutocontrast\n",
      "RandomChoice\n",
      "RandomCrop\n",
      "RandomEqualize\n",
      "RandomErasing\n",
      "RandomGrayscale\n",
      "RandomHorizontalFlip\n",
      "RandomInvert\n",
      "RandomOrder\n",
      "RandomPerspective\n",
      "RandomPosterize\n",
      "RandomResizedCrop\n",
      "RandomRotation\n",
      "RandomSolarize\n",
      "RandomVerticalFlip\n",
      "Resize\n",
      "TenCrop\n",
      "ToPILImage\n",
      "ToTensor\n",
      "TrivialAugmentWide\n"
     ]
    }
   ],
   "source": [
    "#数据预处理\n",
    "from torchvision import transforms\n",
    "# 查看定义数据预处理操作\n",
    "import inspect\n",
    "transform_methods = [name for name, obj in inspect.getmembers(transforms)\n",
    "                     if inspect.isclass(obj) or inspect.isfunction(obj)]\n",
    "\n",
    "# 打印结果\n",
    "print(f\"共找到 {len(transform_methods)} 个 transforms 方法：\")\n",
    "for name in sorted(transform_methods):\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca3d911",
   "metadata": {},
   "source": [
    "上面这个单元格的输出体现了Transform有很多种**对于数据进行预处理**的方法\n",
    "\n",
    "你也可以理解为Transform可以对数据进行增强\n",
    "\n",
    "不过我们一般来说,使用compose方法可以交叉使用多种方法\n",
    "\n",
    "其实常见的就那几种:剪裁,放大,随机翻转,以及crop\n",
    "\n",
    "然后,ToTensor和Normalize方法是必须的,进行向量化和归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "614fed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "##用法,常见套路\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),#常用的归一化参数\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa06c65",
   "metadata": {},
   "source": [
    "OK定义完数据处理的方法之后\n",
    "\n",
    "我们就可以进行加载数据集了\n",
    "\n",
    "这里有两种方法,一种是加载标准数据集,一种是加载自定义数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a65236",
   "metadata": {},
   "source": [
    "### 方法一：加载标准数据集\n",
    "标准数据集就是torch库里面自带的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3df6da4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共找到 72 个数据集：\n",
      "CIFAR10\n",
      "CIFAR100\n",
      "CLEVRClassification\n",
      "CREStereo\n",
      "Caltech101\n",
      "Caltech256\n",
      "CarlaStereo\n",
      "CelebA\n",
      "Cityscapes\n",
      "CocoCaptions\n",
      "CocoDetection\n",
      "Country211\n",
      "DTD\n",
      "DatasetFolder\n",
      "EMNIST\n",
      "ETH3DStereo\n",
      "EuroSAT\n",
      "FER2013\n",
      "FGVCAircraft\n",
      "FakeData\n",
      "FallingThingsStereo\n",
      "FashionMNIST\n",
      "Flickr30k\n",
      "Flickr8k\n",
      "Flowers102\n",
      "FlyingChairs\n",
      "FlyingThings3D\n",
      "Food101\n",
      "GTSRB\n",
      "HD1K\n",
      "HMDB51\n",
      "INaturalist\n",
      "ImageFolder\n",
      "ImageNet\n",
      "Imagenette\n",
      "InStereo2k\n",
      "KMNIST\n",
      "Kinetics\n",
      "Kitti\n",
      "Kitti2012Stereo\n",
      "Kitti2015Stereo\n",
      "KittiFlow\n",
      "LFWPairs\n",
      "LFWPeople\n",
      "LSUN\n",
      "LSUNClass\n",
      "MNIST\n",
      "Middlebury2014Stereo\n",
      "MovingMNIST\n",
      "Omniglot\n",
      "OxfordIIITPet\n",
      "PCAM\n",
      "PhotoTour\n",
      "Places365\n",
      "QMNIST\n",
      "RenderedSST2\n",
      "SBDataset\n",
      "SBU\n",
      "SEMEION\n",
      "STL10\n",
      "SUN397\n",
      "SVHN\n",
      "SceneFlowStereo\n",
      "Sintel\n",
      "SintelStereo\n",
      "StanfordCars\n",
      "UCF101\n",
      "USPS\n",
      "VOCDetection\n",
      "VOCSegmentation\n",
      "VisionDataset\n",
      "WIDERFace\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "import inspect\n",
    "datasets_classes = [name for name,obj in inspect.getmembers(datasets)if inspect.isclass(obj) and issubclass(obj,datasets.VisionDataset)]\n",
    "print(f\"共找到 {len(datasets_classes)} 个数据集：\")\n",
    "for name in sorted(datasets_classes):\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a29d93",
   "metadata": {},
   "source": [
    "上面的单元格输出体现了torch库里自带了多种数据集\n",
    "下面是如何一键下载这些数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38a175fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./测试datasets库里的标准数据集\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./测试datasets库里的标准数据集\\cifar-10-python.tar.gz to ./测试datasets库里的标准数据集\n"
     ]
    }
   ],
   "source": [
    "#用法 ,下载这个datasets的标准数据集,\n",
    "dataset=datasets.CIFAR10(root='./测试datasets库里的标准数据集',train=True,transform=transform,download=True)\n",
    "\n",
    "#dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be1a625",
   "metadata": {},
   "source": [
    "但是我们很多情况下都是有自己的数据集,那该怎么对文件夹进行加载呢?\n",
    "\n",
    "pytorch提供了一个Dataset的抽象类,我们只需继承这个抽象类\n",
    "\n",
    "然后在里面定义3个方法就行了.(from torch.utils.data import Dataset)这样导入抽象类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2baa3d",
   "metadata": {},
   "source": [
    "### 方法二 加载自定义数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08173efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集长度: 3\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np \n",
    "#自定义数据集类,只需要重写三种方法\n",
    "#__init__初始化,__len__获取长度,以及__getitem__进行对象的切片\n",
    "\n",
    "#假设对文件夹train_and_label进行自定义类读取\n",
    "#该文件夹有两个子集,img是特征值,label是标签值\n",
    "class SegmentationDataset(Dataset):\n",
    "  \n",
    "  #1.第一个方法,初始化参数和方法\n",
    "  def __init__(self, img_dir, label_dir, transform=None) -> None:\n",
    "    super().__init__()\n",
    "    self.img_dir = img_dir  # 存储图像文件夹路径\n",
    "    self.label_dir = label_dir  # 存储标签文件夹路径\n",
    "    self.transform = transform  # 数据增强操作\n",
    "    self.img_names = os.listdir(img_dir)  # 获取图像文件名,将文件名存在列表img_names里\n",
    "    \n",
    "    \n",
    "  #2. 第二个方法,返回数据的大小\n",
    "  def __len__(self):\n",
    "    return len(self.img_names)\n",
    "    pass\n",
    "  #3. 第三个方法,如何读取数据,如何进行数据增强\n",
    "  def __getitem__(self,idx):\n",
    "    img_name=self.img_names[idx]\n",
    "    img_path=os.path.join(self.img_dir,img_name) #进行单个数据的名称的路径合并\n",
    "    label_name=img_name.split('.')[0]+'.png'     #通过split,其'.'前面部分拼接上后缀\n",
    "    label_path=os.path.join(self.label_dir,label_name)\n",
    "    \n",
    "    #接下来打开图像\n",
    "    img=Image.open(img_path).convert('RGB')\n",
    "    label=Image.open(label_path).convert('L')   #因为标签值是语义分割,所以就是要转化为灰度图\n",
    "    \n",
    "    #判断一下有没有数据增强的方法\n",
    "    if(self.transform):\n",
    "      img=self.transform(img)      #一般img是输入,可以随便数据增强,\n",
    "      label = torch.tensor(np.array(label), dtype=torch.long)  #标签值就不能Transform数据增强了,转个向量就行\n",
    "    \n",
    "    return img,label #返回一下,数据集的切片返回特征值img和标签值label\n",
    "\n",
    "#测试一下\n",
    "dataset=SegmentationDataset(\n",
    "  img_dir='./train_and_label/img',\n",
    "  label_dir='./train_and_label/label',\n",
    "  transform=transform\n",
    ")\n",
    "print(f\"数据集长度: {len(dataset)}\")#输出3,没问题!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b51212fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T000000.jpg', 'T000002.jpg', 'T000003.jpg']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#测试一下如何读取文件夹里的文件名?\n",
    "#用os.listdir()函数\n",
    "import os\n",
    "img_name=os.listdir(\"train_and_label/img\")\n",
    "img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ff15df98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np \n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, img_dir, label_dir, transforms=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        self.img_names = os.listdir(img_dir)  # 获取图像文件名\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_names[idx] # idx = 0\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        \n",
    "        label_name = os.path.splitext(img_name)[0] + \".png\"\n",
    "        label_path = os.path.join(self.label_dir, label_name)\n",
    "\n",
    "        # 加载图片和标签\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # 转换为 RGB 图像\n",
    "        label = Image.open(label_path).convert(\"L\")  # 转换为单通道图像\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            label = torch.tensor(np.array(label), dtype=torch.long)  # 转换为张量\n",
    "        \n",
    "        return image, label\n",
    "data = SegmentationDataset(\n",
    "    img_dir='train_and_label/img',\n",
    "    label_dir='train_and_label/label',\n",
    "    transforms=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff55877e",
   "metadata": {},
   "source": [
    "接下来我们来看数据集的划分\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0478fb33",
   "metadata": {},
   "source": [
    "## Step2.数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92bf1b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8708f3",
   "metadata": {},
   "source": [
    "## Step3.数据集读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f479b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8917d14c",
   "metadata": {},
   "source": [
    "# 2.模型搭建"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752d649c",
   "metadata": {},
   "source": [
    "## 方法一 容器搭建\n",
    "适用于比较简单,层数比较小的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "474e81fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=3072, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "#model = nn.Sequential(nn.Linear(784, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "model=nn.Sequential(\n",
    "  nn.Linear(32*32*3, 256),  # 假设输入图像大小为32x32，3个通道,256是中间隐藏层的神经元数量\n",
    "  nn.ReLU(),\n",
    "  nn.Linear(256, 10)  # 假设输出是10个类别\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff35e1f",
   "metadata": {},
   "source": [
    "## 方法二 自定义模型\n",
    "模型比较复杂"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925e365f",
   "metadata": {},
   "source": [
    "重写一个nn中的Module抽象类\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "33282f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.nn import Module\n",
    "class MLP(Module):\n",
    "   \n",
    "    def __init__(self, input_size,hidden_size,output_size) -> None:\n",
    "        #super(MLP,self).__init__()\n",
    "        super().__init__()\n",
    "        self.fc1=nn.Linear(input_size,hidden_size)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.fc2=nn.Linear(hidden_size,output_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.fc1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.fc2(x)\n",
    "        return x\n",
    "model=MLP(input_size=784,hidden_size=256,output_size=10)\n",
    "print(model)       \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40caf9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "class MLP(Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model = MLP(input_size=784, hidden_size=256, output_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9b64cc",
   "metadata": {},
   "source": [
    "# 3.损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eeeb2347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38043b99",
   "metadata": {},
   "source": [
    "# 4.优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "17dc05b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbffe52",
   "metadata": {},
   "source": [
    "# 5.模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "58b78419",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (192x32 and 784x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m loss_all \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs,labels \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[1;32m----> 6\u001b[0m     outputs\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     loss_value\u001b[38;5;241m=\u001b[39mcriterion(outputs,labels)\n\u001b[0;32m      8\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# 清除梯度\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\day1_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\day1_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[49], line 13\u001b[0m, in \u001b[0;36mMLP.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[1;32m---> 13\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m     15\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\day1_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\day1_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\day1_env\\lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (192x32 and 784x256)"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    loss_all = 0.0\n",
    "    for inputs,labels in train_dataloader:\n",
    "        outputs=model(inputs)\n",
    "        loss_value=criterion(outputs,labels)\n",
    "        optimizer.zero_grad()  # 清除梯度\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "        loss_all += loss_value.item() * inputs.size(0)\n",
    "    epoch_loss = loss_all / len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70fb0ee9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (192x32 and 784x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_dataloader:        \n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# 前向传播\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# 反向传播和优化\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\day1_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\day1_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[34], line 13\u001b[0m, in \u001b[0;36mMLP.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[1;32m---> 13\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m     15\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\day1_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\day1_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\day1_env\\lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (192x32 and 784x256)"
     ]
    }
   ],
   "source": [
    "num_epochs = 5  # 设置训练的轮数\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_dataloader:        \n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "        loss.backward()        # 计算梯度\n",
    "        optimizer.step()       # 更新权重\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # 计算准确率\n",
    "        _, predicted = torch.max(outputs, 1)  # 选择最大概率的类别\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataloader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "273d897f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print(inputs.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
